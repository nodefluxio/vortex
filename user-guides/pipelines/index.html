<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Pipelines - Vortex</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/ir-black.min.css">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/console.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../..">Vortex</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../.." class="nav-link">Home</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">User Guides <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../dataset_integration/" class="dropdown-item">Dataset Integration</a>
</li>
                                    
<li>
    <a href="../experiment_file_config/" class="dropdown-item">Experiment File Configuration</a>
</li>
                                    
<li>
    <a href="../hypopt_file_config/" class="dropdown-item">HypOpt File Configuration</a>
</li>
                                    
<li>
    <a href="./" class="dropdown-item active">Pipelines</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Developer Guides <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../developer-guides/custom_backbone_integration/" class="dropdown-item">Custom Backbone Integration</a>
</li>
                                    
<li>
    <a href="../../developer-guides/custom_model_integration_classification/" class="dropdown-item">Custom Model Integration : Classification</a>
</li>
                                    
<li>
    <a href="../../developer-guides/custom_model_integration_detection/" class="dropdown-item">Custom Model Integration : Detection</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Modules <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../modules/builtin_dataset/" class="dropdown-item">Built-in Dataset</a>
</li>
                                    
<li>
    <a href="../../modules/logging_provider/" class="dropdown-item">Logging Provider</a>
</li>
                                    
<li>
    <a href="../../modules/augmentation/" class="dropdown-item">Augmentations</a>
</li>
                                    
<li>
    <a href="../../modules/data_loader/" class="dropdown-item">Data Loader</a>
</li>
                                    
<li>
    <a href="../../modules/scheduler/" class="dropdown-item">Learning Rates Scheduler</a>
</li>
                                    
<li>
    <a href="../../modules/train_driver/" class="dropdown-item">Training Driver</a>
</li>
                                    
<li>
    <a href="../../modules/models_zoo/" class="dropdown-item">Models Zoo</a>
</li>
                                    
<li>
    <a href="../../modules/backbones/" class="dropdown-item">Backbones Network</a>
</li>
                                    
<li>
    <a href="../../modules/exporter/" class="dropdown-item">Graph Exporter</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../api/vortex.development.core.pipelines/" class="dropdown-item">vortex.development.core.pipelines</a>
</li>
                                    
<li>
    <a href="../../api/vortex.development.core.factory/" class="dropdown-item">vortex.development.core.factory</a>
</li>
                                    
<li>
    <a href="../../api/vortex.runtime/" class="dropdown-item">vortex.runtime</a>
</li>
                                </ul>
                            </li>
                            <li class="navitem">
                                <a href="https://github.com/nodefluxio/vortex" class="nav-link">Repository</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../hypopt_file_config/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../../developer-guides/custom_backbone_integration/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#vortex-pipelines" class="nav-link">Vortex Pipelines</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#training-pipeline" class="nav-link">Training Pipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#validation-pipeline" class="nav-link">Validation Pipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#prediction-pipeline" class="nav-link">Prediction Pipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#hyperparameters-optimization-pipeline" class="nav-link">Hyperparameters Optimization Pipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#graph-export-pipeline" class="nav-link">Graph Export Pipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#ir-validation-pipeline" class="nav-link">IR Validation Pipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#ir-prediction-pipeline" class="nav-link">IR Prediction Pipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="vortex-pipelines">Vortex Pipelines<a class="headerlink" href="#vortex-pipelines" title="Permanent link">&para;</a></h1>
<p>This section will describe how to easily run each of Vortex pipeline in details. For complete pipelines flow please see <a href="../..#overview">Vortex overview section</a></p>
<hr />
<h2 id="training-pipeline">Training Pipeline<a class="headerlink" href="#training-pipeline" title="Permanent link">&para;</a></h2>
<p>This pipeline purpose is to train a deep learning model using the provided dataset. If you need to integrate the training into your own script you can see the <a href="../../api/vortex.development.core.pipelines/#trainingpipeline">training pipeline API section</a>.</p>
<p>To run this pipeline, make sure you've already prepared :</p>
<ul>
<li><strong>Dataset</strong> : see <a href="../../modules/builtin_dataset/">this section</a> for built-in datasets, or <a href="../dataset_integration/">this section</a> for external datasets</li>
<li><strong>Experiment file</strong> : see <a href="../experiment_file_config/">this section</a> to create one</li>
</ul>
<p>and additionally, if you want to <strong>resume previous training</strong> or <strong>load pretrained model</strong>, you also need :</p>
<ul>
<li><strong>Vortex model's file</strong> <code>*.pth</code> : obtained from previously executed training pipeline which corresponds to the previous mentioned experiment file. Specific checkpoint file on several epoch can be found under <strong>run directory</strong> ( see outputs of this training pipeline section ). This file must be configured in experiment file under <a href="../experiment_file_config/#checkpoint"><code>checkpoint</code></a> section</li>
</ul>
<p>You only need to run this command from the command line interface :</p>
<pre><code class="language-console">usage: vortex train [-h] -c CONFIG [--resume] [--no-log]

Vortex training pipeline; will generate a Pytorch model file

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        path to experiment config file
  --resume              vortex-saved model path for resume training
  --no-log              disable logging, ignore experiment file config
</code></pre>
<p>E.g. :</p>
<pre><code class="language-console">vortex train -c experiments/config/efficientnet_b0_classification_cifar10.yml
</code></pre>
<p>This pipeline will generate several outputs :</p>
<ul>
<li>
<p><strong>Local runs log file</strong> : every time a user runs a VORTEX training experiment, the experiment logger module will write a local file <code>experiments/local_runs.log</code> which will record all experimental training runs which have already executed sequentially for easier tracking. Example of the content inside <code>experiments/local_runs.log</code> is shown below :</p>
<pre><code>###############################################################################
Timestamp : 03/27/2020, 09:24:00
Experiment Name : test_torchvision_dataset
Output Path : experiments/outputs/test_torchvision_dataset/601f45782a884286be310b1ffe562597
Logging Provider : comet_ml
Experiment Log URL : https://www.comet.ml/hyperion-rg/vortex-dev/601f45782a884286be310b1ffe562597
###############################################################################
</code></pre>
</li>
<li>
<p><strong>Experiment directory</strong> : If not exist yet, training script will make a directory under the configured <code>output_directory</code> path. The created directory will be named after the <code>experiment_name</code> configuration and will be the directory to dump training (final weight), validation result (if any), backup, etc.</p>
</li>
<li>
<p><strong>Run directory</strong> : Everytime user runs the training script, it will be tagged as a new experiment run. Vortex (or third party logger) will generate a unique key which will be an identifier for that specific experiment run. And thus, Vortex will make a new directory under the experiment directory which will act as a backup directory. It will store the duplicate of the executed experiment file (as a backup) and will be the directory which store intermediate model’s weight path (weight that saved every n-epoch). For example, in the previous example log the output path is :</p>
<pre><code>Output Path : experiments/outputs/test_torchvision_dataset/601f45782a884286be310b1ffe562597
</code></pre>
<p>The experiment directory is <code>test_torchvision_dataset</code> and the run directory is <code>601f45782a884286be310b1ffe562597</code></p>
</li>
<li>
<p><strong>Backup experiment file</strong> : Experiment file will be duplicated and stored under <strong>run directory</strong></p>
</li>
<li>
<p><strong>Intermediate model file</strong> : File containing model’s weight and training checkpoint will be dumped into <strong>run directory</strong> with <code>.pth</code> extension,which can be controlled from 2 experiment file <code>trainer</code> parameter, <code>save_epoch</code> and <code>save_best_metrics</code> :</p>
<ul>
<li><code>save_epoch</code> : save checkpoint every <em>n</em>-epoch</li>
<li><code>save_best_metrics</code> : save checkpoint based on monitored metrics</li>
</ul>
</li>
<li>
<p><strong>Final model file</strong> : File containing model's weight and training checkpoint after all training epoch is completed will be dumped in the <strong>run directory</strong> and <strong>experiment directory</strong> with <code>.pth</code> extension. </p>
<p><strong>WARNING</strong> : if you have multiple experiment run with the same <code>experiment_name</code>, each finished run will overwrite this final model file in the <strong>experiment_directory</strong>, however the original final model file will still exist on the <strong>run_directory</strong></p>
</li>
<li>
<p><strong>Experiment log</strong> : If logging is enabled, training metrics will be collected by the logging provider. Additionally if the config file is valid for validation, the validation metrics will also be collected.</p>
</li>
</ul>
<hr />
<h2 id="validation-pipeline">Validation Pipeline<a class="headerlink" href="#validation-pipeline" title="Permanent link">&para;</a></h2>
<p>This pipeline handle the evaluation of the Vortex model (Pytorch state dict <code>.pth</code>) in term of model's performance and resource usage. In addition, this pipeline also generate a visual report. If you need to integrate the validation into your own script you can see the <a href="../../api/vortex.development.core.pipelines/#pytorchvalidationpipeline">validation pipeline API section</a>.</p>
<p>To run this pipeline, make sure you've already prepared :</p>
<ul>
<li><strong>Validation dataset</strong> : see <a href="../../modules/builtin_dataset/">this section</a> for built-in datasets, or <a href="../dataset_integration/">this section</a> for external datasets</li>
<li><strong>Experiment file</strong> : see <a href="../experiment_file_config/">this section</a> to create one. Must be valid for validation, make sure <a href="../experiment_file_config/#dataset"><code>dataset.eval</code></a> and <a href="../experiment_file_config/#trainer"><code>validator</code></a> is set</li>
<li><strong>Vortex model's file</strong> <code>*.pth</code> : obtained from <a href="#training-pipeline">training pipeline</a> which corresponds to the previous mentioned experiment file</li>
</ul>
<p>You only need to run this command from the command line interface :</p>
<pre><code class="language-console">usage: vortex validate [-h] -c CONFIG [-w WEIGHTS] [-v] [--quiet]
                       [-d [DEVICES [DEVICES ...]]] [-b BATCH_SIZE]

Vortex Pytorch model validation pipeline; successful runs will produce
autogenerated reports

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        path to experiment config
  -w WEIGHTS, --weights WEIGHTS
                        path to selected weights(optional, will be inferred
                        from `output_directory` and `experiment_name` field
                        from config) if not specified
  -v, --verbose         verbose prediction output
  --quiet
  -d [DEVICES [DEVICES ...]], --devices [DEVICES [DEVICES ...]]
                        computation device to be used for prediction, possible
                        to list multiple devices
  -b BATCH_SIZE, --batch-size BATCH_SIZE
                        batch size for validation
</code></pre>
<p><strong>NOTES</strong> : if <code>--weights</code> is not provided, Vortex will assume final weights exist in the <strong>experiment directory</strong></p>
<p>E.g. :</p>
<pre><code class="language-console">vortex validate -c experiments/config/efficientnet_b0_classification_cifar10.yml \
                -b 8 \
                -d cpu cuda
</code></pre>
<p>This pipeline will generate several outputs :</p>
<ul>
<li><strong>Report file</strong> : after successful evaluation, report file will be generated under directory <code>reports</code> in the <strong>experiment directory</strong> based on <code>experiment_name</code> under <code>output_directory</code>. Pro Tip : the generated report could be easily converted to pdf using <a href="https://pandoc.org/demos.html">pandoc</a> or <a href="https://marketplace.visualstudio.com/items?itemName=yzane.markdown-pdf">vscode markdown-pdf extension</a>.</li>
</ul>
<hr />
<h2 id="prediction-pipeline">Prediction Pipeline<a class="headerlink" href="#prediction-pipeline" title="Permanent link">&para;</a></h2>
<p>This pipeline is used to test and visualize your Vortex model's prediction. If you need to integrate the prediction into your own script you can see the <a href="../../api/vortex.development.core.pipelines/#pytorchpredictionpipeline">prediction pipeline API section</a>.</p>
<p>To run this pipeline, make sure you've already prepared :</p>
<ul>
<li><strong>Experiment file</strong> : see <a href="../experiment_file_config/">this section</a> to create one</li>
<li><strong>Vortex model's file</strong> <code>*.pth</code> : obtained from <a href="#training-pipeline">training pipeline</a> which corresponds to the previous mentioned experiment file</li>
<li><strong>Input image(s)</strong> : image file(s) (tested with <code>*.jpg</code>,<code>*.jpeg</code>,<code>*.png</code> extension)</li>
</ul>
<p>You only need to run this command from the command line interface :</p>
<pre><code class="language-console">usage: vortex predict [-h] -c CONFIG [-w WEIGHTS] [-o OUTPUT_DIR] -i IMAGE
                      [IMAGE ...] [-d DEVICE]
                      [--score_threshold SCORE_THRESHOLD]
                      [--iou_threshold IOU_THRESHOLD]

Vortex Pytorch model prediction pipeline; may receive multiple image(s) for
batched prediction

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        path to experiment config
  -w WEIGHTS, --weights WEIGHTS
                        path to selected weights(optional, will be inferred
                        from `output_directory` and `experiment_name` field
                        from config) if not specified
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        directory to dump prediction visualization
  -i IMAGE [IMAGE ...], --image IMAGE [IMAGE ...]
                        path to test image(s)
  -d DEVICE, --device DEVICE
                        the device in which the inference will be performed
  --score_threshold SCORE_THRESHOLD
                        score threshold for detection, only used if model is
                        detection, ignored otherwise
  --iou_threshold IOU_THRESHOLD
                        iou threshold for nms, , only used if model is
                        detection, ignored otherwise
</code></pre>
<p><strong>NOTES</strong> : if <code>--weights</code> is not provided, Vortex will assume final weights exist in the <strong>experiment directory</strong></p>
<p>E.g. :</p>
<pre><code class="language-console">vortex predict -c experiments/config/efficientnet_b0_classification_cifar10.yml \
               -i image1.jpg image2.jpg \
               -d cuda \
               -o output_vis
</code></pre>
<p><strong>NOTES</strong> : Provided multiple input images will be treated as batch input</p>
<p>This pipeline will generate several outputs :</p>
<ul>
<li><strong>Output Visualization Directory</strong> : if <code>--output_dir</code> is provided, it will create the directory in your current working directory</li>
<li><strong>Prediction Visualization</strong> : prediction visualization will be generated in the <code>--output_dir</code> if provided, or in the current working dir if not. The generated file will have <code>prediction_</code> name prefix.</li>
</ul>
<hr />
<h2 id="hyperparameters-optimization-pipeline">Hyperparameters Optimization Pipeline<a class="headerlink" href="#hyperparameters-optimization-pipeline" title="Permanent link">&para;</a></h2>
<p>This pipeline is used to search for optimum hyperparameter to be used for either training pipeline or validation pipeline (parameter in validation pipeline also can be used for prediction pipeline). Basically this pipeline is <a href="https://optuna.org/">Optuna</a> wrapper for Vortex components. If you need to integrate the prediction into your own script you can see the <a href="../../api/vortex.development.core.pipelines/#hypoptpipeline">hyperparameters optimization pipeline API section</a>.</p>
<p>To run this pipeline, make sure you've already prepared :</p>
<ul>
<li><strong>Hypopt config file</strong> : see <a href="../hypopt_file_config/">this section</a> to create one</li>
<li><strong>Experiment file</strong> : see <a href="../experiment_file_config/">this section</a> to create one</li>
<li><strong>Vortex model's file</strong> <code>*.pth</code> : obtained from <a href="#training-pipeline">training pipeline</a> which corresponds to the previous mentioned experiment file</li>
<li>Related objective's pipeline requirement</li>
</ul>
<p>You only need to run this command from the command line interface :</p>
<pre><code class="language-console">usage: vortex hypopt [-h] -c CONFIG -o OPTCONFIG [-w WEIGHTS]

Vortex hyperparameter optimization experiment

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        path to experiment config file
  -o OPTCONFIG, --optconfig OPTCONFIG
                        path to hypopt config file
  -w WEIGHTS, --weights WEIGHTS
                        path to selected weights (optional, will be inferred
                        from `output_directory` and `experiment_name` field
                        from config) if not specified, valid only for
                        ValidationObjective, ignored otherwise
</code></pre>
<p><strong>NOTES</strong> : if <code>--weights</code> is not provided, Vortex will assume final weights exist in the <strong>experiment directory</strong></p>
<p>E.g. :</p>
<pre><code class="language-console">vortex hypopt -c experiments/config/efficientnet_b0_classification_cifar10.yml \
              -o experiments/hypopt/learning_rate_search.yml
</code></pre>
<p>This pipeline will generate several outputs :</p>
<ul>
<li><strong>Hypopt Output Dir</strong> : <code>hypopt/{hypopt_study_name}</code> will be created under <strong>experiment directory</strong></li>
<li><strong>Best Parameters</strong> : file <code>*.txt</code> containing best parameters will be created in <strong>hypopt output dir</strong></li>
<li><strong>Hypopt Visualization</strong> : graph visualization of parameter search (visualization extension must be installed. see <a href="../..#installation">installation section</a>) will be created in <strong>hypopt output dir</strong></li>
</ul>
<hr />
<h2 id="graph-export-pipeline">Graph Export Pipeline<a class="headerlink" href="#graph-export-pipeline" title="Permanent link">&para;</a></h2>
<p>This pipeline is used to export trained Vortex model (or graph) into another graph representation (or Intermediate Representation (IR)). If you need to integrate the graph export pipeline into your own script you can see the <a href="../../api/vortex.development.core.pipelines/#graphexportpipeline">graph export pipeline API section</a>.</p>
<p>To run this pipeline, make sure you've already prepared :</p>
<ul>
<li><strong>Experiment file</strong> : see <a href="../experiment_file_config/">this section</a> to create one and make sure the <code>exporter</code> section is already configured</li>
<li><strong>Vortex model's file</strong> <code>*.pth</code> : obtained from <a href="#training-pipeline">training pipeline</a> which corresponds to the previous mentioned experiment file</li>
<li><strong>Example Input Image</strong> : example input image for correct graph tracing. Recommended for using image from training dataset and strongly recommended for model with detection task</li>
</ul>
<p>You only need to run this command from the command line interface :</p>
<pre><code class="language-console">usage: vortex export [-h] -c CONFIG [-w WEIGHTS] [-i EXAMPLE_INPUT]

export model to specific IR specified in config, output IR are stored in the
experiment directory based on `experiment_name` under `output_directory`
config field, after successful export, you should be able to visualize the
network using [netron](https://lutzroeder.github.io/netron/)

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        export experiment config file
  -w WEIGHTS, --weights WEIGHTS
                        path to selected weights (optional, will be inferred
                        from `output_directory` and `experiment_name` field
                        from config) if not specified
  -i EXAMPLE_INPUT, --example-input EXAMPLE_INPUT
                        path to example input for tracing (optional, may be
                        necessary for correct tracing, especially for
                        detection model)
</code></pre>
<p><strong>NOTES</strong> : if <code>--weights</code> is not provided, Vortex will assume final weights exist in the <strong>experiment directory</strong></p>
<p>E.g. :</p>
<pre><code class="language-console">vortex export -c experiments/config/efficientnet_b0_classification_cifar10.yml -i image1.jpg
</code></pre>
<p>This pipeline will generate several outputs :</p>
<ul>
<li><strong>IR model file</strong> : IR model file will be created under <strong>experiment directory</strong>, with file extension that correspond to <a href="../../modules/exporter/"><code>exporter</code></a> settings</li>
</ul>
<hr />
<h2 id="ir-validation-pipeline">IR Validation Pipeline<a class="headerlink" href="#ir-validation-pipeline" title="Permanent link">&para;</a></h2>
<p>This pipeline handle the evaluation of the IR model (<code>*.pt</code> or <code>*.onnx</code>) in term of model's performance and resource usage. In addition, this pipeline also generate a visual report. If you need to integrate the validation into your own script you can see the <a href="../../api/vortex.development.core.pipelines/#irvalidationpipeline">IR validation pipeline API section</a>.</p>
<p>To run this pipeline, make sure you've already prepared :</p>
<ul>
<li><strong>Validation dataset</strong> : see <a href="../../modules/builtin_dataset/">this section</a> for built-in datasets, or <a href="../dataset_integration/">this section</a> for external datasets</li>
<li><strong>Experiment file</strong> : see <a href="../experiment_file_config/">this section</a> to create one. Must be valid for validation, make sure <a href="../experiment_file_config/#dataset"><code>dataset.eval</code></a> and <a href="../experiment_file_config/#trainer"><code>validator</code></a> is set</li>
<li><strong>IR model file</strong> <code>*.pt</code> or <code>*.onnx</code> : obtained from <a href="#graph-export-pipeline">graph export pipeline</a></li>
<li><strong>IR runtime library and environment</strong> : make sure runtime library and environment is installed (currently runtime library installed together with vortex)</li>
</ul>
<p>You only need to run this command from the command line interface :</p>
<pre><code class="language-console">usage: vortex ir_runtime_validate [-h] -c CONFIG -m MODEL
                                  [-r [RUNTIME [RUNTIME ...]]] [-v] [--quiet]
                                  [--batch-size BATCH_SIZE]

Vortex exported IR graph validation pipeline; successful runs will produce
autogenerated reports

optional arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        path to experiment config including dataset fields,
                        must be valid for validation, dataset.eval will be
                        used for evaluation
  -m MODEL, --model MODEL
                        path to IR model
  -r [RUNTIME [RUNTIME ...]], --runtime [RUNTIME [RUNTIME ...]]
                        runtime backend device
  -v, --verbose         verbose prediction output
  --quiet
  -b BATCH_SIZE, --batch-size BATCH_SIZE
                        batch size for validation; NOTE : passed value should
                        be matched with exported model batch size
</code></pre>
<p>E.g. :</p>
<pre><code class="language-console">vortex ir_runtime_validate -c experiments/config/efficientnet_b0_classification_cifar10.yml \
                           -m experiments/outputs/efficientnet_b0_classification_cifar10/efficientnet_b0_classification_cifar10.pt \
                           -b 8 \
                           -r cpu cuda
</code></pre>
<p>This pipeline will generate several outputs :</p>
<ul>
<li><strong>Report file</strong> : after successful evaluation, report file will be generated under directory <code>reports</code> in the <strong>experiment directory</strong> based on <code>experiment_name</code> under <code>output_directory</code>. Pro Tip : the generated report could be easily converted to pdf using <a href="https://pandoc.org/demos.html">pandoc</a> or <a href="https://marketplace.visualstudio.com/items?itemName=yzane.markdown-pdf">vscode markdown-pdf extension</a>.</li>
</ul>
<hr />
<h2 id="ir-prediction-pipeline">IR Prediction Pipeline<a class="headerlink" href="#ir-prediction-pipeline" title="Permanent link">&para;</a></h2>
<p>This pipeline is used to test and visualize your IR model's (<code>*.pt</code> or <code>*.onnx</code>) prediction. If you need to integrate the prediction into your own script you can see the <a href="../../api/vortex.development.core.pipelines/#irpredictionpipeline">IR prediction pipeline API section</a>.</p>
<p>To run this pipeline, make sure you've already prepared :</p>
<ul>
<li><strong>IR model file</strong> <code>*.pt</code> or <code>*.onnx</code> : obtained from <a href="#graph-export-pipeline">graph export pipeline</a></li>
<li><strong>IR runtime library and environment</strong> : make sure runtime library and environment is installed (currently runtime library installed together with vortex)</li>
<li><strong>Input image(s)</strong> : image file(s) (tested with <code>*.jpg</code>,<code>*.jpeg</code>,<code>*.png</code> extension)</li>
</ul>
<p>You only need to run this command from the command line interface :</p>
<pre><code class="language-console">usage: vortex ir_runtime_predict [-h] -m MODEL -i IMAGE [IMAGE ...]
                                 [-o OUTPUT_DIR]
                                 [--score_threshold SCORE_THRESHOLD]
                                 [--iou_threshold IOU_THRESHOLD] [-r RUNTIME]

Vortex IR model prediction pipeline; may receive multiple image(s) for batched
prediction

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        path to IR model
  -i IMAGE [IMAGE ...], --image IMAGE [IMAGE ...]
                        path to test image(s); at least 1 path should be
                        provided, supports up to model batch_size
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        directory to dump prediction visualization
  --score_threshold SCORE_THRESHOLD
                        score threshold for detection, only used if model is
                        detection, ignored otherwise
  --iou_threshold IOU_THRESHOLD
                        iou threshold for nms, only used if model is
                        detection, ignored otherwise
  -r RUNTIME, --runtime RUNTIME
                        runtime device

</code></pre>
<p>E.g. :</p>
<pre><code class="language-console">vortex ir_runtime_predict -c experiments/config/efficientnet_b0_classification_cifar10.yml \
                          -m experiments/outputs/efficientnet_b0_classification_cifar10/efficientnet_b0_classification_cifar10.pt \
                          -i image1.jpg image2.jpg \
                          -r cuda \
                          -o output_vis
</code></pre>
<p><strong>NOTES</strong> : Provided multiple input images will be treated as batch input. Vortex IR model is strict with batch size, means that provided input batch size must match with Vortex IR <a href="../../modules/exporter/"><code>exporter</code></a> batch size configuration.</p>
<p>This pipeline will generate several outputs :</p>
<ul>
<li><strong>Output Visualization Directory</strong> : if <code>--output_dir</code> is provided, it will create the directory in your current working directory</li>
<li><strong>Prediction Visualization</strong> : prediction visualization will be generated in the <code>--output_dir</code> if provided, or in the current working dir if not. The generated file will have <code>prediction_</code> name prefix.</li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
