<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>vortex.development.core.pipelines - Vortex</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/ir-black.min.css">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/console.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../..">Vortex</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../.." class="nav-link">Home</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">User Guides <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../user-guides/dataset_integration/" class="dropdown-item">Dataset Integration</a>
</li>
                                    
<li>
    <a href="../../user-guides/experiment_file_config/" class="dropdown-item">Experiment File Configuration</a>
</li>
                                    
<li>
    <a href="../../user-guides/hypopt_file_config/" class="dropdown-item">HypOpt File Configuration</a>
</li>
                                    
<li>
    <a href="../../user-guides/pipelines/" class="dropdown-item">Pipelines</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Developer Guides <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../developer-guides/custom_backbone_integration/" class="dropdown-item">Custom Backbone Integration</a>
</li>
                                    
<li>
    <a href="../../developer-guides/custom_model_integration_classification/" class="dropdown-item">Custom Model Integration : Classification</a>
</li>
                                    
<li>
    <a href="../../developer-guides/custom_model_integration_detection/" class="dropdown-item">Custom Model Integration : Detection</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Modules <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../modules/builtin_dataset/" class="dropdown-item">Built-in Dataset</a>
</li>
                                    
<li>
    <a href="../../modules/logging_provider/" class="dropdown-item">Logging Provider</a>
</li>
                                    
<li>
    <a href="../../modules/augmentation/" class="dropdown-item">Augmentations</a>
</li>
                                    
<li>
    <a href="../../modules/data_loader/" class="dropdown-item">Data Loader</a>
</li>
                                    
<li>
    <a href="../../modules/scheduler/" class="dropdown-item">Learning Rates Scheduler</a>
</li>
                                    
<li>
    <a href="../../modules/train_driver/" class="dropdown-item">Training Driver</a>
</li>
                                    
<li>
    <a href="../../modules/models_zoo/" class="dropdown-item">Models Zoo</a>
</li>
                                    
<li>
    <a href="../../modules/backbones/" class="dropdown-item">Backbones Network</a>
</li>
                                    
<li>
    <a href="../../modules/exporter/" class="dropdown-item">Graph Exporter</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="./" class="dropdown-item active">vortex.development.core.pipelines</a>
</li>
                                    
<li>
    <a href="../vortex.development.core.factory/" class="dropdown-item">vortex.development.core.factory</a>
</li>
                                    
<li>
    <a href="../vortex.runtime/" class="dropdown-item">vortex.runtime</a>
</li>
                                </ul>
                            </li>
                            <li class="navitem">
                                <a href="https://github.com/nodefluxio/vortex" class="nav-link">Repository</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../../modules/exporter/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../vortex.development.core.factory/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#vortexdevelopmentcorepipelines" class="nav-link">vortex.development.core.pipelines</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#classes" class="nav-link">Classes</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="3"><a href="#graphexportpipeline" class="nav-link">GraphExportPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#hypoptpipeline" class="nav-link">HypOptPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#pytorchpredictionpipeline" class="nav-link">PytorchPredictionPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#irpredictionpipeline" class="nav-link">IRPredictionPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#trainingpipeline" class="nav-link">TrainingPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#pytorchvalidationpipeline" class="nav-link">PytorchValidationPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#irvalidationpipeline" class="nav-link">IRValidationPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="vortexdevelopmentcorepipelines">vortex.development.core.pipelines<a class="headerlink" href="#vortexdevelopmentcorepipelines" title="Permanent link">&para;</a></h1>
<hr />
<hr />
<h2 id="classes">Classes<a class="headerlink" href="#classes" title="Permanent link">&para;</a></h2>
<hr />
<hr />
<h3 id="graphexportpipeline">GraphExportPipeline<a class="headerlink" href="#graphexportpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Graph Export Pipeline API</p>
<h4 id="__init__"><code>__init__</code><a class="headerlink" href="#__init__" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def __init__(
      self,
      config : easydict.EasyDict,
      weights : typing.Union[str, pathlib.Path, NoneType] = None,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - dictionary parsed from Vortex experiment file</li>
<li><code>weights</code> <em>Union[str,Path], optional</em> - path to selected Vortex model's weight. If set to None, it will                                                  assume that final model weights exist in <strong>experiment directory</strong>.                                                  Defaults to None.</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">from vortex.development.utils.parser import load_config
from vortex.development.core.pipelines import GraphExportPipeline

# Parse config
config = load_config('experiments/config/example.yml')
graph_exporter = GraphExportPipeline(config=config,
                                     weights='experiments/outputs/example/example.pth')
</code></pre>
<hr />
<h4 id="run"><code>run</code><a class="headerlink" href="#run" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def run(
      self,
      example_input : typing.Union[str, pathlib.Path, NoneType] = None,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>example_input</code> <em>Union[str,Path], optional</em> - path to example input image to help graph tracing. 
Defaults to None.</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary containing status of the export process</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">example_input = 'image1.jpg'
graph_exporter = GraphExportPipeline(config=config,
                                     weights='experiments/outputs/example/example.pth')

result = graph_exporter.run(example_input=example_input)
</code></pre>
<hr />
<hr />
<h3 id="hypoptpipeline">HypOptPipeline<a class="headerlink" href="#hypoptpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Hyperparameters Optimization Pipeline API</p>
<h4 id="__init___1"><code>__init__</code><a class="headerlink" href="#__init___1" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def __init__(
      self,
      config : easydict.EasyDict,
      optconfig : easydict.EasyDict,
      weights : typing.Union[str, pathlib.Path, NoneType] = None,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - dictionary parsed from Vortex experiment file</li>
<li><code>optconfig</code> <em>EasyDict</em> - dictionary parsed from Vortex hypopt configuration file</li>
<li><code>weights</code> <em>Union[str,Path,None], optional</em> - path to selected Vortex model's weight. If set to None, it will                                                       assume that final model weights exist in <strong>experiment directory</strong>.                                                       Only used for ValidationObjective. Defaults to None.</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">from vortex.development.core.pipelines import HypOptPipeline
from vortex.development.utils.parser.loader import Loader
import yaml

# Parse config
config_path = 'experiments/config/example.yml'
optconfig_path = 'experiments/hypopt/learning_rate_search.yml'

with open(config_path) as f:
    config_data = yaml.load(f, Loader=Loader)
with open(optconfig_path) as f:
    optconfig_data = yaml.load(f, Loader=Loader)

graph_exporter = HypOptPipeline(config=config,
                                optconfig=optconfig)
</code></pre>
<hr />
<h4 id="run_1"><code>run</code><a class="headerlink" href="#run_1" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def run(
      self,
)
</code></pre>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary containing result of the hypopt process</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">graph_exporter = HypOptPipeline(config=config,
                                optconfig=optconfig)
results = graph_exporter.run()
</code></pre>
<hr />
<hr />
<h3 id="pytorchpredictionpipeline">PytorchPredictionPipeline<a class="headerlink" href="#pytorchpredictionpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Prediction Pipeline API for Vortex model</p>
<h4 id="__init___2"><code>__init__</code><a class="headerlink" href="#__init___2" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def __init__(
      self,
      config : easydict.EasyDict,
      weights : typing.Union[str, pathlib.Path, NoneType] = None,
      device : typing.Union[str, NoneType] = None,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - dictionary parsed from Vortex experiment file</li>
<li><code>weights</code> <em>Union[str,Path,None], optional</em> - path to selected Vortex model's weight. If set to None, it will                                                       assume that final model weights exist in <strong>experiment directory</strong>.                                                       Defaults to None.</li>
<li><code>device</code> <em>Union[str,None], optional</em> - selected device for model's computation. If None, it will use the device                                                 described in <strong>experiment file</strong>. Defaults to None.</li>
</ul>
<p><strong>Raises</strong>:</p>
<ul>
<li><code>FileNotFoundError</code> - raise error if selected 'weights' file is not found</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">from vortex.development.core.pipelines import PytorchPredictionPipeline
from vortex.development.utils.parser import load_config

# Parse config
config_path = 'experiments/config/example.yml'
config = load_config(config_path)
weights_file = 'experiments/outputs/example/example.pth'
device = 'cuda'

vortex_predictor = PytorchPredictionPipeline(config = config,
                                           weights = weights_file,
                                           device = device)
</code></pre>
<hr />
<h4 id="run_2"><code>run</code><a class="headerlink" href="#run_2" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def run(
      self,
      images : typing.Union[typing.List[str], numpy.ndarray],
      output_coordinate_format: str = &quot;relative&quot;,
      visualize : bool = False,
      dump_visual : bool = False,
      output_dir : typing.Union[str, pathlib.Path] = '.',
      **kwargs,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>images</code> <em>Union[List[str],np.ndarray]</em> - list of images path or array of image</li>
<li><code>output_coordinate_format</code> <em>str, optional</em> - output coordinate format, especially usefull for models that returns
      coordinates in the input, e.g. bounding box, landmark, etc. Available: 
      <code>'relative'</code>: the coordinate is relative to input size (have range of [0, 1]), so to visualize the output needs to be multplied by input size; 
      <code>'absolute'</code>: the coordinate is absolute to input size (range of [widht, height]). 
      Default <code>'relative'</code>.</li>
<li><code>visualize</code> <em>bool, optional</em> - option to return prediction visualization. Defaults to False.</li>
<li><code>dump_visual</code> <em>bool, optional</em> - option to dump prediction visualization. Defaults to False.</li>
<li><code>output_dir</code> <em>Union[str,Path], optional</em> - directory path to dump visualization. Defaults to '.' .</li>
<li><code>kwargs</code> <em>optional</em> - forwarded to model's forward pass, so this kwargs is placement for additional input parameters, 
      make sure to have this if your model needs an additional inputs, e.g. <code>score_threshold</code>, etc.</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary of prediction result</li>
</ul>
<p><strong>Raises</strong>:</p>
<ul>
<li><code>TypeError</code> - raise error if provided 'images' is not list of image path or array of images</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">
# Initialize prediction pipeline
vortex_predictor=PytorchPredictionPipeline(config = config,
                                           weights = weights_file,
                                           device = device)

## OR
vortex_predictor=IRPredictionPipeline(model = model_file,
                                      runtime = runtime)

# You can get model's required parameter by extracting model's 'input_specs' attributes

input_shape  = vortex_predictor.model.input_specs['input']['shape']

## `input_specs['input']['shape']` will provide (batch_size,height,width,channel) dimension
## NOTES : PytorchPredictionPipeline can accept flexible batch size,
## however the `input_specs['input']['shape']` of the batch_size dimension 
## will always set to 1, ignore this

# Extract additional run() input parameters specific for each model

additional_run_params = [key for key in vortex_predictor.model.input_specs.keys() if key!='input']
print(additional_run_params)

## Assume that the model is detection model
## ['score_threshold', 'iou_threshold'] &lt;&lt; this parameter must be provided in run() arguments

# Prepare batched input from image files path
batch_input = ['image1.jpg','image2.jpg']

## OR
import cv2
input_size = input_shape[1] # Assume square input
image1 = cv2.resize(cv2.imread('image1.jpg'), (input_size,input_size))
image2 = cv2.resize(cv2.imread('image2.jpg'), (input_size,input_size))
batch_input = np.array([image1,image2])

results = vortex_predictor.run(images=batch_input,
                               score_threshold=0.9,
                               iou_threshold=0.2)

# Additional process : obtain class_names from model
class_names = vortex_predictor.model.class_names
print(class_names)

</code></pre>
<hr />
<hr />
<h3 id="irpredictionpipeline">IRPredictionPipeline<a class="headerlink" href="#irpredictionpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Prediction Pipeline API for Vortex IR model</p>
<h4 id="__init___3"><code>__init__</code><a class="headerlink" href="#__init___3" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def __init__(
      self,
      model : typing.Union[str, pathlib.Path],
      runtime : str = 'cpu',
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>model</code> <em>Union[str,Path]</em> - path to Vortex IR model, file with extension '.onnx' or '.pt'</li>
<li><code>runtime</code> <em>str, optional</em> - backend runtime to be selected for model's computation. Defaults to 'cpu'.</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">from vortex.development.core.pipelines import IRPredictionPipeline
from vortex.development.utils.parser import load_config

# Parse config
model_file = 'experiments/outputs/example/example.pt' # Model file with extension '.onnx' or '.pt'
runtime = 'cpu'

vortex_predictor=IRPredictionPipeline(model = model_file,
                                      runtime = runtime)
</code></pre>
<hr />
<h4 id="run_3"><code>run</code><a class="headerlink" href="#run_3" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def run(
      self,
      images : typing.Union[typing.List[str], numpy.ndarray],
      output_coordinate_format: str = &quot;relative&quot;,
      visualize : bool = False,
      dump_visual : bool = False,
      output_dir : typing.Union[str, pathlib.Path] = '.',
      **kwargs,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>images</code> <em>Union[List[str],np.ndarray]</em> - list of images path or array of image</li>
<li><code>output_coordinate_format</code> <em>str, optional</em> - output coordinate format, especially usefull for models that returns
      coordinates in the input, e.g. bounding box, landmark, etc. Available: 
      <code>'relative'</code>: the coordinate is relative to input size (have range of [0, 1]), so to visualize the output needs to be multplied by input size; 
      <code>'absolute'</code>: the coordinate is absolute to input size (range of [widht, height]). 
      Default <code>'relative'</code>.</li>
<li><code>visualize</code> <em>bool, optional</em> - option to return prediction visualization. Defaults to False.</li>
<li><code>dump_visual</code> <em>bool, optional</em> - option to dump prediction visualization. Defaults to False.</li>
<li><code>output_dir</code> <em>Union[str,Path], optional</em> - directory path to dump visualization. Defaults to '.' .</li>
<li><code>kwargs</code> <em>optional</em> - forwarded to model's forward pass, so this kwargs is placement for additional input parameters, 
      make sure to have this if your model needs an additional inputs, e.g. <code>score_threshold</code>, etc.</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary of prediction result</li>
</ul>
<p><strong>Raises</strong>:</p>
<ul>
<li><code>TypeError</code> - raise error if provided 'images' is not list of image path or array of images</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">
# Initialize prediction pipeline
vortex_predictor=PytorchPredictionPipeline(config = config,
                                           weights = weights_file,
                                           device = device)

## OR
vortex_predictor=IRPredictionPipeline(model = model_file,
                                      runtime = runtime)

# You can get model's required parameter by extracting model's 'input_specs' attributes

input_shape  = vortex_predictor.model.input_specs['input']['shape']

## `input_specs['input']['shape']` will provide (batch_size,height,width,channel) dimension
## NOTES : PytorchPredictionPipeline can accept flexible batch size,
## however the `input_specs['input']['shape']` of the batch_size dimension 
## will always set to 1, ignore this

# Extract additional run() input parameters specific for each model

additional_run_params = [key for key in vortex_predictor.model.input_specs.keys() if key!='input']
print(additional_run_params)

## Assume that the model is detection model
## ['score_threshold', 'iou_threshold'] &lt;&lt; this parameter must be provided in run() arguments

# Prepare batched input from image files path
batch_input = ['image1.jpg','image2.jpg']

## OR
import cv2
input_size = input_shape[1] # Assume square input
image1 = cv2.resize(cv2.imread('image1.jpg'), (input_size,input_size))
image2 = cv2.resize(cv2.imread('image2.jpg'), (input_size,input_size))
batch_input = np.array([image1,image2])

results = vortex_predictor.run(images=batch_input,
                               score_threshold=0.9,
                               iou_threshold=0.2)

# Additional process : obtain class_names from model
class_names = vortex_predictor.model.class_names
print(class_names)

</code></pre>
<hr />
<hr />
<h3 id="trainingpipeline">TrainingPipeline<a class="headerlink" href="#trainingpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Training Pipeline API</p>
<h4 id="__init___4"><code>__init__</code><a class="headerlink" href="#__init___4" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def __init__(
      self,
      config : easydict.EasyDict,
      config_path : typing.Union[str, pathlib.Path, NoneType] = None,
      hypopt : bool = False,
      resume : bool = False,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - dictionary parsed from Vortex experiment file</li>
<li><code>config_path</code> <em>Union[str,Path,None], optional</em> - path to experiment file. 
Need to be provided for backup <strong>experiment file</strong>. 
Defaults to None.</li>
<li><code>hypopt</code> <em>bool, optional</em> - flag for hypopt, disable several pipeline process. 
Defaults to False.</li>
<li><code>resume</code> <em>bool, optional</em> - flag to resume training. 
Defaults to False.</li>
</ul>
<p><strong>Raises</strong>:</p>
<ul>
<li><code>Exception</code> - raise undocumented error if exist</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">from vortex.development.utils.parser import load_config
from vortex.development.core.pipelines import TrainingPipeline

# Parse config
config_path = 'experiments/config/example.yml'
config = load_config(config_path)
train_executor = TrainingPipeline(config=config,
                                  config_path=config_path,
                                  hypopt=False)
</code></pre>
<hr />
<h4 id="run_4"><code>run</code><a class="headerlink" href="#run_4" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def run(
      self,
      save_model : bool = True,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>save_model</code> <em>bool, optional</em> - dump model's checkpoint. Defaults to True.</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary containing loss, val results and learning rates history</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">train_executor = TrainingPipeline(config=config,
                                  config_path=config_path,
                                  hypopt=False)
outputs = train_executor.run()
</code></pre>
<hr />
<hr />
<h3 id="pytorchvalidationpipeline">PytorchValidationPipeline<a class="headerlink" href="#pytorchvalidationpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Validation Pipeline API for Vortex model</p>
<h4 id="__init___5"><code>__init__</code><a class="headerlink" href="#__init___5" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def __init__(
      self,
      config : easydict.EasyDict,
      weights : typing.Union[str, pathlib.Path, NoneType] = None,
      backends : typing.Union[list, str] = [],
      generate_report : bool = True,
      hypopt : bool = False,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - dictionary parsed from Vortex experiment file</li>
<li><code>weights</code> <em>Union[str,Path,None], optional</em> - path to selected Vortex model's weight. If set to None, it will                                                       assume that final model weights exist in <strong>experiment directory</strong>.                                                       Defaults to None.</li>
<li><code>backends</code> <em>Union[list,str], optional</em> - device(s) to be used for validation process. If not provided,                                                   it will use the device described in <strong>experiment file</strong>. Defaults to [].</li>
<li><code>generate_report</code> <em>bool, optional</em> - if enabled will generate validation report in markdown format. Defaults to True.</li>
<li><code>hypopt</code> <em>bool, optional</em> - flag for hypopt, disable several pipeline process. Defaults to False.</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">from vortex.development.utils.parser import load_config
from vortex.development.core.pipelines import PytorchValidationPipeline

# Parse config
config_path = 'experiments/config/example.yml'
weights_file = 'experiments/outputs/example/example.pth'
backends = ['cpu','cuda']
config = load_config(config_path)
validation_executor = PytorchValidationPipeline(config=config,
                                                weights = weights_file,
                                                backends = backends,
                                                generate_report = True)
</code></pre>
<hr />
<h4 id="run_5"><code>run</code><a class="headerlink" href="#run_5" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def run(
      self,
      batch_size : int = 1,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>batch_size</code> <em>int, optional</em> - size of validation input batch. Defaults to 1.</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary containing validation metrics result</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">
# Initialize validation pipeline
validation_executor = PytorchValidationPipeline(config=config,
                                                weights = weights_file,
                                                backends = backends,
                                                generate_report = True)
## OR
validation_executor = IRValidationPipeline(config=config,
                                           model = model_file,
                                           backends = backends,
                                           generate_report = True)

# Run validation process
results = validation_executor.run(batch_size = 2)

## OR (for IRValidationPipeline only, PytorchValidationPipeline can accept flexible batch size)
## 'batch_size' information is embedded in model.input_specs['input']['shape'][0]

batch_size = validation_executor.model.input_specs['input']['shape'][0]
results = validation_executor.run(batch_size = batch_size)
</code></pre>
<hr />
<hr />
<h3 id="irvalidationpipeline">IRValidationPipeline<a class="headerlink" href="#irvalidationpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Validation Pipeline API for Vortex IR model</p>
<h4 id="__init___6"><code>__init__</code><a class="headerlink" href="#__init___6" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def __init__(
      self,
      config : easydict.EasyDict,
      model : typing.Union[str, pathlib.Path, NoneType],
      backends : typing.Union[list, str] = ['cpu'],
      generate_report : bool = True,
      hypopt : bool = False,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - ictionary parsed from Vortex experiment file</li>
<li><code>model</code> <em>Union[str,Path,None]</em> - path to Vortex IR model, file with extension '.onnx' or '.pt'</li>
<li><code>backends</code> <em>Union[list,str], optional</em> - runtime(s) to be used for validation process. Defaults to ['cpu'].</li>
<li><code>generate_report</code> <em>bool, optional</em> - if enabled will generate validation report in markdown format. Defaults to True.</li>
<li><code>hypopt</code> <em>bool, optional</em> - flag for hypopt, disable several pipeline process. Defaults to False.</li>
</ul>
<p><strong>Raises</strong>:</p>
<ul>
<li><code>RuntimeError</code> - raise error if the provided model file's extension is not '<em>.onnx' or '</em>.pt'</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">from vortex.development.utils.parser import load_config
from vortex.development.core.pipelines import IRValidationPipeline

# Parse config
config_path = 'experiments/config/example.yml'
model_file = 'experiments/outputs/example/example.pt'
backends = ['cpu','cuda']
config = load_config(config_path)
validation_executor = IRValidationPipeline(config=config,
                                           model = model_file,
                                           backends = backends,
                                           generate_report = True)
</code></pre>
<hr />
<h4 id="run_6"><code>run</code><a class="headerlink" href="#run_6" title="Permanent link">&para;</a></h4>
<pre><code class="language-python">def run(
      self,
      batch_size : int = 1,
)
</code></pre>
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>batch_size</code> <em>int, optional</em> - size of validation input batch. Defaults to 1.</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary containing validation metrics result</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="language-python">
# Initialize validation pipeline
validation_executor = PytorchValidationPipeline(config=config,
                                                weights = weights_file,
                                                backends = backends,
                                                generate_report = True)
## OR
validation_executor = IRValidationPipeline(config=config,
                                           model = model_file,
                                           backends = backends,
                                           generate_report = True)

# Run validation process
results = validation_executor.run(batch_size = 2)

## OR (for IRValidationPipeline only, PytorchValidationPipeline can accept flexible batch size)
## 'batch_size' information is embedded in model.input_specs['input']['shape'][0]

batch_size = validation_executor.model.input_specs['input']['shape'][0]
results = validation_executor.run(batch_size = batch_size)
</code></pre>
<hr /></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
